{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ground_state",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcsrygb0bEM0KQqX8ODTqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onurdurhan/Mytest/blob/master/ground_state.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiZZnay0Zsr0"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import numpy as np                                  \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFQDE6QPbMYQ",
        "outputId": "2e2b8284-61f2-47b5-c77e-ed1e93915afe"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print(\"Cuda (GPU support) is available and enabled!\")\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  print(\"Cuda (GPU support) is not available :(\")\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda (GPU support) is not available :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mzXWeHbcbvc"
      },
      "source": [
        "def riemann(b_n,psy,x):\n",
        "  dx=abs(x[-1])/len(x)\n",
        "  projection=sum(b_n*psy*dx)\n",
        "  return projection"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZLukLhMcnsm"
      },
      "source": [
        "#x=np.linspace(0., 1., 100)\n",
        "x = torch.unsqueeze(torch.linspace(0., 1., 100), dim=1)\n",
        "x=Variable(x)\n",
        "#x = Variable(torch.Tensor(np.array(x)))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K78JSFjrbWRX"
      },
      "source": [
        "class TwoLayerNet(nn.Module):\n",
        "    def __init__(self, D, H, C):\n",
        "        super(TwoLayerNet, self).__init__()\n",
        "        #torch.manual_seed(501)        \n",
        "        self.fc1 = nn.Linear(D,H)\n",
        "        self.fc = nn.Linear(H,H)\n",
        "        self.fc2 = nn.Linear(H,C)\n",
        "\n",
        "    def forward(self, x):\n",
        "      print(\"before\",x.shape)\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.fc(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2mzz7rjuUQQ"
      },
      "source": [
        "def hamiltonian_loss(output,N,x):\n",
        "  loss=0.0\n",
        "  a=1.\n",
        "  amplitude=0.0\n",
        "  for n in range(1,N):\n",
        "    H_nn=(math.pi**2)*(n**2)/2.\n",
        "    decomposition=riemann(math.sqrt(2./a)*torch.sin(n*x*torch.tensor(math.pi)/a),output,x)\n",
        "    loss+=H_nn*abs(decomposition)**2\n",
        "    amplitude+=decomposition**2\n",
        "  loss=loss/(amplitude)\n",
        "  return loss "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4lHVwoZvROL"
      },
      "source": [
        "def perturbed_loss(output,N,x):\n",
        "  a=1.\n",
        "  M=100\n",
        "  N=100\n",
        "  alpha = 8.\n",
        "  decompositions=torch.zeros(M)\n",
        "  x_nm=torch.zeros((N,M))\n",
        "  for n in range(N):\n",
        "    for m in range(M):\n",
        "      decompositions[m]= riemann(math.sqrt(2./a)*torch.sin((m+1)*x*math.pi/a),output,x)\n",
        "      if not m == n:\n",
        "        x_nm[n][m] = (math.cos((n-m)*math.pi)-1)/(n-m)**2-(math.cos((n+m)*math.pi)-1)/(n+m)**2\n",
        "        x_nm[n][m] = x_nm[n][m]*a/math.pi**2\n",
        "      if m == n :\n",
        "        x_nm[n][m] = a/2.\n",
        "  decompositions=torch.tensor(decompositions)\n",
        "  x_loc = x_nm*decompositions\n",
        "  x_loc=torch.tensor(x_loc)\n",
        "  loss = alpha*torch.sum((x_loc.sum(dim=1)*decompositions**2))/torch.sum(decompositions**3)\n",
        "  loss = Variable(loss, requires_grad = True)+hamiltonian_loss(output,N,x)\n",
        "  return loss"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOI36cs53ygV"
      },
      "source": [
        "def train(model, criterion, optimizer, epochs,x, verbose=True):\n",
        "  loss_history=[]\n",
        "  # Train the model\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    outputs = model(x)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "  \n",
        "    loss = criterion(outputs, 100,x)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    loss_history.append(loss.item())\n",
        "    if verbose: print(f'Epoch {epoch} / {epochs}: avg. loss of last 5 iterations {np.sum(loss_history[:-6:-1])/5}')\n",
        "  return loss_history   "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "9KXly6eLjazn",
        "outputId": "5aaf26df-dd11-447a-ab23-b29f480344c9"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "D = 1\n",
        "C = 1 \n",
        "H = 1000 s\n",
        "epochs=1000\n",
        "learning_rate=0.0002\n",
        "model = TwoLayerNet(D, H, C)\n",
        "\n",
        "#criterion = hamiltonian_loss\n",
        "#criterion = perturbed_loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_history=train(model,criterion,optimizer,epochs,x)\n",
        "plt.plot(loss_history)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-192152d86a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#criterion = perturbed_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mloss_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQRpwkN8lumh"
      },
      "source": [
        "model.eval()\n",
        "predicted = model(x)\n",
        "predicted = predicted.data.numpy()\n",
        "plt.plot(x,predicted)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CCEfrjPpt_q"
      },
      "source": [
        "class PerturbedNet(nn.Module):\n",
        "    def __init__(self, D, H1, H2):\n",
        "        super(PerturbedNet, self).__init__()\n",
        "        #torch.manual_seed(501)        \n",
        "        self.fc1 = nn.Linear(D,H1)\n",
        "        self.fc = nn.Linear(H1,H2)\n",
        "        self.fc2 = nn.Linear(H2,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.fc(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZxvJDEMqEfF",
        "outputId": "0bc9e2c8-26ac-4221-cb8c-49d33d1dd3db"
      },
      "source": [
        "D = 1\n",
        "H1 = 500\n",
        "H2 = 100\n",
        "epochs=100\n",
        "learning_rate=0.0000002\n",
        "model = PerturbedNet(D, H1, H2)\n",
        "criterion = perturbed_loss\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "loss_history=train(model,criterion,optimizer,epochs,x)\n",
        "plt.plot(loss_history)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 / 100: avg. loss of last 5 iterations 23.56107940673828\n",
            "Epoch 1 / 100: avg. loss of last 5 iterations 46.99229888916015\n",
            "Epoch 2 / 100: avg. loss of last 5 iterations 70.29753875732422\n",
            "Epoch 3 / 100: avg. loss of last 5 iterations 93.48065948486328\n",
            "Epoch 4 / 100: avg. loss of last 5 iterations 116.5421356201172\n",
            "Epoch 5 / 100: avg. loss of last 5 iterations 115.92152099609375\n",
            "Epoch 6 / 100: avg. loss of last 5 iterations 115.30795135498047\n",
            "Epoch 7 / 100: avg. loss of last 5 iterations 114.69684600830078\n",
            "Epoch 8 / 100: avg. loss of last 5 iterations 114.08281707763672\n",
            "Epoch 9 / 100: avg. loss of last 5 iterations 113.48115997314453\n",
            "Epoch 10 / 100: avg. loss of last 5 iterations 112.89178314208985\n",
            "Epoch 11 / 100: avg. loss of last 5 iterations 112.31478576660156\n",
            "Epoch 12 / 100: avg. loss of last 5 iterations 111.74916534423828\n",
            "Epoch 13 / 100: avg. loss of last 5 iterations 111.19446868896485\n",
            "Epoch 14 / 100: avg. loss of last 5 iterations 110.63250427246093\n",
            "Epoch 15 / 100: avg. loss of last 5 iterations 110.062646484375\n",
            "Epoch 16 / 100: avg. loss of last 5 iterations 109.50435485839844\n",
            "Epoch 17 / 100: avg. loss of last 5 iterations 108.9606430053711\n",
            "Epoch 18 / 100: avg. loss of last 5 iterations 108.4341323852539\n",
            "Epoch 19 / 100: avg. loss of last 5 iterations 107.92388305664062\n",
            "Epoch 20 / 100: avg. loss of last 5 iterations 107.42803955078125\n",
            "Epoch 21 / 100: avg. loss of last 5 iterations 106.92806549072266\n",
            "Epoch 22 / 100: avg. loss of last 5 iterations 106.42027587890625\n",
            "Epoch 23 / 100: avg. loss of last 5 iterations 105.90314331054688\n",
            "Epoch 24 / 100: avg. loss of last 5 iterations 105.3777587890625\n",
            "Epoch 25 / 100: avg. loss of last 5 iterations 104.84393768310547\n",
            "Epoch 26 / 100: avg. loss of last 5 iterations 104.30057525634766\n",
            "Epoch 27 / 100: avg. loss of last 5 iterations 103.75015106201172\n",
            "Epoch 28 / 100: avg. loss of last 5 iterations 103.19033508300781\n",
            "Epoch 29 / 100: avg. loss of last 5 iterations 102.6186538696289\n",
            "Epoch 30 / 100: avg. loss of last 5 iterations 102.03395233154296\n",
            "Epoch 31 / 100: avg. loss of last 5 iterations 101.43446197509766\n",
            "Epoch 32 / 100: avg. loss of last 5 iterations 100.81651458740234\n",
            "Epoch 33 / 100: avg. loss of last 5 iterations 100.18000793457031\n",
            "Epoch 34 / 100: avg. loss of last 5 iterations 99.52526245117187\n",
            "Epoch 35 / 100: avg. loss of last 5 iterations 98.85602416992188\n",
            "Epoch 36 / 100: avg. loss of last 5 iterations 98.16479034423828\n",
            "Epoch 37 / 100: avg. loss of last 5 iterations 97.44946899414063\n",
            "Epoch 38 / 100: avg. loss of last 5 iterations 96.70787658691407\n",
            "Epoch 39 / 100: avg. loss of last 5 iterations 95.93769989013671\n",
            "Epoch 40 / 100: avg. loss of last 5 iterations 95.13114929199219\n",
            "Epoch 41 / 100: avg. loss of last 5 iterations 94.29736633300782\n",
            "Epoch 42 / 100: avg. loss of last 5 iterations 93.42938385009765\n",
            "Epoch 43 / 100: avg. loss of last 5 iterations 92.5235580444336\n",
            "Epoch 44 / 100: avg. loss of last 5 iterations 91.6113784790039\n",
            "Epoch 45 / 100: avg. loss of last 5 iterations 90.72579956054688\n",
            "Epoch 46 / 100: avg. loss of last 5 iterations 89.86556091308594\n",
            "Epoch 47 / 100: avg. loss of last 5 iterations 89.04657440185547\n",
            "Epoch 48 / 100: avg. loss of last 5 iterations 88.25986175537109\n",
            "Epoch 49 / 100: avg. loss of last 5 iterations 87.47132873535156\n",
            "Epoch 50 / 100: avg. loss of last 5 iterations 86.65426025390624\n",
            "Epoch 51 / 100: avg. loss of last 5 iterations 85.80294494628906\n",
            "Epoch 52 / 100: avg. loss of last 5 iterations 84.90211944580078\n",
            "Epoch 53 / 100: avg. loss of last 5 iterations 83.95546112060546\n",
            "Epoch 54 / 100: avg. loss of last 5 iterations 82.95250244140625\n",
            "Epoch 55 / 100: avg. loss of last 5 iterations 81.89454956054688\n",
            "Epoch 56 / 100: avg. loss of last 5 iterations 80.72821197509765\n",
            "Epoch 57 / 100: avg. loss of last 5 iterations 79.45325164794922\n",
            "Epoch 58 / 100: avg. loss of last 5 iterations 78.05879211425781\n",
            "Epoch 59 / 100: avg. loss of last 5 iterations 76.55439453125\n",
            "Epoch 60 / 100: avg. loss of last 5 iterations 74.89381713867188\n",
            "Epoch 61 / 100: avg. loss of last 5 iterations 73.10316162109375\n",
            "Epoch 62 / 100: avg. loss of last 5 iterations 71.16241149902343\n",
            "Epoch 63 / 100: avg. loss of last 5 iterations 69.02288818359375\n",
            "Epoch 64 / 100: avg. loss of last 5 iterations 66.61307907104492\n",
            "Epoch 65 / 100: avg. loss of last 5 iterations 63.899827575683595\n",
            "Epoch 66 / 100: avg. loss of last 5 iterations 60.7575065612793\n",
            "Epoch 67 / 100: avg. loss of last 5 iterations 57.064082336425784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0YX5V6Bq9bL"
      },
      "source": [
        "model.eval()\n",
        "predicted = model(x)\n",
        "predicted = predicted.data.numpy()\n",
        "plt.plot(x,predicted)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}